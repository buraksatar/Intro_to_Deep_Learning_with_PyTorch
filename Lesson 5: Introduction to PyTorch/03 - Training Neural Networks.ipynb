{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is the slope of the loss function and points in the direction of fastest change.\n",
    "\n",
    "Backpropagation is really just an application of the chain rule from calculus.\n",
    "\n",
    "The goal is to adjust the weights and biases to minimize the loss.\n",
    "\n",
    "We update our weights using this gradient with some learning rate.\n",
    "\n",
    "*nn.CrossEntropyLoss* contains of *nn.LogSoftmax()* and *nn.NLLLoss()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "\n",
    "# Download and load the trainin data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',\n",
    "                          download=True,\n",
    "                          train=True,\n",
    "                          transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3064, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2887, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
    "\n",
    "To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set *requires_grad=True* on a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, requires_grad=True)\n",
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can turn on or off gradients altogether with *torch.set_grad_enabled(True|False)*\n",
    "\n",
    "The gradients are computed with respect to some variable z with z.backward(). This does a backward pass through the operations that created z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5407, -0.3887],\n",
      "        [-1.1343,  1.4291]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2924, 0.1511],\n",
      "        [1.2867, 2.0424]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f53bea39828>\n"
     ]
    }
   ],
   "source": [
    "# grad_fn shows the function that generated this Variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9431, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the *.backward* method on a Variable, z for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2704, -0.1944],\n",
      "        [-0.5672,  0.7146]])\n",
      "tensor([[-0.2704, -0.1944],\n",
      "        [-0.5672,  0.7146]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the gradients we can make a gradient descent step.\n",
    "\n",
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 6.6671e-04,  6.6671e-04,  6.6671e-04,  ...,  6.6671e-04,\n",
      "          6.6671e-04,  6.6671e-04],\n",
      "        [-3.1967e-04, -3.1967e-04, -3.1967e-04,  ..., -3.1967e-04,\n",
      "         -3.1967e-04, -3.1967e-04],\n",
      "        [-3.3004e-03, -3.3004e-03, -3.3004e-03,  ..., -3.3004e-03,\n",
      "         -3.3004e-03, -3.3004e-03],\n",
      "        ...,\n",
      "        [ 2.1817e-03,  2.1817e-03,  2.1817e-03,  ...,  2.1817e-03,\n",
      "          2.1817e-03,  2.1817e-03],\n",
      "        [ 2.8524e-03,  2.8524e-03,  2.8524e-03,  ...,  2.8524e-03,\n",
      "          2.8524e-03,  2.8524e-03],\n",
      "        [-6.7993e-05, -6.7993e-05, -6.7993e-05,  ..., -6.7993e-05,\n",
      "         -6.7993e-05, -6.7993e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "We need an optimizer to use to update the weights with the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and\n",
    "# a learning rate\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process with PyTorch:\n",
    "- Make a forward pass through the network\n",
    "- Use the network output to calculate the loss\n",
    "- Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
    "- Take a step with the optimizer to update the weights\n",
    "\n",
    "Remember to use *optimizer.zero_grad()*. When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means we need to zero the gradients on each training pass or we'll retain gradients from previous training batches.\n",
    "\n",
    "Here is the one training step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0295, -0.0119, -0.0168,  ...,  0.0261,  0.0348, -0.0116],\n",
      "        [-0.0152,  0.0066, -0.0011,  ...,  0.0141,  0.0269,  0.0354],\n",
      "        [-0.0171,  0.0020,  0.0200,  ...,  0.0196,  0.0241,  0.0237],\n",
      "        ...,\n",
      "        [ 0.0350, -0.0191,  0.0135,  ..., -0.0206,  0.0184, -0.0062],\n",
      "        [ 0.0070,  0.0244,  0.0142,  ..., -0.0082, -0.0132, -0.0078],\n",
      "        [-0.0336,  0.0125,  0.0171,  ...,  0.0145,  0.0023, -0.0148]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[-1.0036e-05, -1.0036e-05, -1.0036e-05,  ..., -1.0036e-05,\n",
      "         -1.0036e-05, -1.0036e-05],\n",
      "        [ 1.8668e-03,  1.8668e-03,  1.8668e-03,  ...,  1.8668e-03,\n",
      "          1.8668e-03,  1.8668e-03],\n",
      "        [ 6.9936e-04,  6.9936e-04,  6.9936e-04,  ...,  6.9936e-04,\n",
      "          6.9936e-04,  6.9936e-04],\n",
      "        ...,\n",
      "        [ 2.4665e-03,  2.4665e-03,  2.4665e-03,  ...,  2.4665e-03,\n",
      "          2.4665e-03,  2.4665e-03],\n",
      "        [-1.5956e-04, -1.5956e-04, -1.5956e-04,  ..., -1.5956e-04,\n",
      "         -1.5956e-04, -1.5956e-04],\n",
      "        [ 1.3468e-03,  1.3468e-03,  1.3468e-03,  ...,  1.3468e-03,\n",
      "          1.3468e-03,  1.3468e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass and update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0295, -0.0119, -0.0168,  ...,  0.0261,  0.0348, -0.0116],\n",
      "        [-0.0152,  0.0066, -0.0011,  ...,  0.0141,  0.0269,  0.0354],\n",
      "        [-0.0171,  0.0020,  0.0200,  ...,  0.0196,  0.0241,  0.0237],\n",
      "        ...,\n",
      "        [ 0.0350, -0.0191,  0.0135,  ..., -0.0206,  0.0184, -0.0062],\n",
      "        [ 0.0070,  0.0244,  0.0142,  ..., -0.0082, -0.0132, -0.0078],\n",
      "        [-0.0336,  0.0125,  0.0171,  ...,  0.0145,  0.0023, -0.0148]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Initial weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for real\n",
    "\n",
    "one pass through the entire dataset is called an epoch. \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Implement the training pass for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:                 1.83877502473941\n",
      "Training loss:                 0.7996465953618987\n",
      "Training loss:                 0.5178606588480823\n",
      "Training loss:                 0.4257783250355009\n",
      "Training loss:                 0.3812331702313952\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass, get our logits\n",
    "        logits = model(images)\n",
    "        # Calculate the loss with the logits and the labels\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        # Take an update step and few the new weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: \\\n",
    "                {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53b875ce10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "# output the network are log-probabilities,\n",
    "# need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
