{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data',\n",
    "                                 download=True,\n",
    "                                 train=True,\n",
    "                                 transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data',\n",
    "                                 download=True,\n",
    "                                 train=False,\n",
    "                                 transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8484b37668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84880ed2b0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 233,
       "width": 233
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion\n",
    "# and optimizer\n",
    "\n",
    "model = fc_model.Network(784, \n",
    "                         10, \n",
    "                         [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.738..  Test Loss: 1.000..  Test Accuracy: 0.642\n",
      "Epoch: 1/2..  Training Loss: 1.021..  Test Loss: 0.744..  Test Accuracy: 0.719\n",
      "Epoch: 1/2..  Training Loss: 0.863..  Test Loss: 0.692..  Test Accuracy: 0.739\n",
      "Epoch: 1/2..  Training Loss: 0.841..  Test Loss: 0.637..  Test Accuracy: 0.752\n",
      "Epoch: 1/2..  Training Loss: 0.765..  Test Loss: 0.631..  Test Accuracy: 0.756\n",
      "Epoch: 1/2..  Training Loss: 0.731..  Test Loss: 0.599..  Test Accuracy: 0.773\n",
      "Epoch: 1/2..  Training Loss: 0.703..  Test Loss: 0.597..  Test Accuracy: 0.778\n",
      "Epoch: 1/2..  Training Loss: 0.647..  Test Loss: 0.567..  Test Accuracy: 0.786\n",
      "Epoch: 1/2..  Training Loss: 0.683..  Test Loss: 0.551..  Test Accuracy: 0.792\n",
      "Epoch: 1/2..  Training Loss: 0.665..  Test Loss: 0.553..  Test Accuracy: 0.798\n",
      "Epoch: 1/2..  Training Loss: 0.622..  Test Loss: 0.559..  Test Accuracy: 0.787\n",
      "Epoch: 1/2..  Training Loss: 0.603..  Test Loss: 0.532..  Test Accuracy: 0.801\n",
      "Epoch: 1/2..  Training Loss: 0.629..  Test Loss: 0.516..  Test Accuracy: 0.814\n",
      "Epoch: 1/2..  Training Loss: 0.577..  Test Loss: 0.522..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.593..  Test Loss: 0.509..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.608..  Test Loss: 0.527..  Test Accuracy: 0.802\n",
      "Epoch: 1/2..  Training Loss: 0.568..  Test Loss: 0.511..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.616..  Test Loss: 0.518..  Test Accuracy: 0.810\n",
      "Epoch: 1/2..  Training Loss: 0.604..  Test Loss: 0.493..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.573..  Test Loss: 0.491..  Test Accuracy: 0.824\n",
      "Epoch: 1/2..  Training Loss: 0.551..  Test Loss: 0.487..  Test Accuracy: 0.822\n",
      "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.471..  Test Accuracy: 0.829\n",
      "Epoch: 1/2..  Training Loss: 0.598..  Test Loss: 0.486..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.476..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.559..  Test Loss: 0.476..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.557..  Test Loss: 0.486..  Test Accuracy: 0.820\n",
      "Epoch: 2/2..  Training Loss: 0.559..  Test Loss: 0.473..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.476..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.481..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.481..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.543..  Test Loss: 0.460..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.472..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.458..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.485..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.455..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.461..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.490..  Test Loss: 0.461..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.568..  Test Loss: 0.452..  Test Accuracy: 0.843\n",
      "Epoch: 2/2..  Training Loss: 0.510..  Test Loss: 0.456..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.510..  Test Loss: 0.470..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.561..  Test Loss: 0.463..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.502..  Test Loss: 0.465..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.450..  Test Accuracy: 0.841\n",
      "Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.447..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.454..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.538..  Test Loss: 0.442..  Test Accuracy: 0.840\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, \n",
    "               criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading networks\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's *state_dict*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print('Our model: \\n\\n', model, '\\n')\n",
    "print('The state dict keys: \\n\\n', \n",
    "              model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the state dict with *torch.save*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with *torch.load*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the state dick in to the network, we do *model.load_state_dict(state_dict)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!**\n",
    "\n",
    "Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b7713383f520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cv-nd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "# For example\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be save in the checkpoint, along with the state dict. So, we build a dictionary with all the information we need to completely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784, \n",
    "              'output_size': 10, \n",
    "              'hidden_layers' : [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict' : model.state_dict()\n",
    "             }\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the checkpoints has all the necessary information to rebuild the trained model. We can write a function to load checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(\n",
    "                    checkpoint['input_size'], \n",
    "                    checkpoint['output_size'],\n",
    "                    checkpoint['hidden_layers']\n",
    "            )\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
